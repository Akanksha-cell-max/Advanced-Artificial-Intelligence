{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAM84SpMFOUBWqyQhAk4UG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akanksha-cell-max/Advanced-Artificial-Intelligence/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XprVZRIgfQbe",
        "outputId": "6d3353ce-4a46-4981-93e5-10052eac75b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Sample:\n",
            "    Study Hours  Previous Exam Score  Pass/Fail\n",
            "0     4.370861            81.889703          0\n",
            "1     9.556429            72.165782          1\n",
            "2     7.587945            58.571657          0\n",
            "3     6.387926            88.827701          1\n",
            "4     2.404168            81.083870          0\n",
            "Testing Data Sample:\n",
            "    Study Hours  Previous Exam Score  Pass/Fail\n",
            "0     4.370861            81.889703          0\n",
            "1     9.556429            72.165782          1\n",
            "2     7.587945            58.571657          0\n",
            "3     6.387926            88.827701          1\n",
            "4     2.404168            81.083870          0\n",
            "Epoch 1/200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.7002 - loss: 0.6788 - val_accuracy: 0.9100 - val_loss: 0.5542\n",
            "Epoch 2/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8824 - loss: 0.5157 - val_accuracy: 0.9200 - val_loss: 0.4271\n",
            "Epoch 3/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9044 - loss: 0.4326 - val_accuracy: 0.8900 - val_loss: 0.3447\n",
            "Epoch 4/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9225 - loss: 0.3316 - val_accuracy: 0.9000 - val_loss: 0.2922\n",
            "Epoch 5/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9574 - loss: 0.2669 - val_accuracy: 0.8800 - val_loss: 0.2726\n",
            "Epoch 6/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9213 - loss: 0.2462 - val_accuracy: 0.8800 - val_loss: 0.2598\n",
            "Epoch 7/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9343 - loss: 0.2151 - val_accuracy: 0.9000 - val_loss: 0.2437\n",
            "Epoch 8/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9630 - loss: 0.1761 - val_accuracy: 0.8900 - val_loss: 0.2371\n",
            "Epoch 9/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9534 - loss: 0.1707 - val_accuracy: 0.9100 - val_loss: 0.2257\n",
            "Epoch 10/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9613 - loss: 0.1562 - val_accuracy: 0.9000 - val_loss: 0.2194\n",
            "Epoch 11/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9592 - loss: 0.1606 - val_accuracy: 0.9100 - val_loss: 0.2054\n",
            "Epoch 12/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9574 - loss: 0.1538 - val_accuracy: 0.9200 - val_loss: 0.1968\n",
            "Epoch 13/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9565 - loss: 0.1676 - val_accuracy: 0.9500 - val_loss: 0.1820\n",
            "Epoch 14/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9630 - loss: 0.1328 - val_accuracy: 0.9300 - val_loss: 0.1777\n",
            "Epoch 15/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9557 - loss: 0.1458 - val_accuracy: 0.9500 - val_loss: 0.1661\n",
            "Epoch 16/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9710 - loss: 0.1279 - val_accuracy: 0.9400 - val_loss: 0.1630\n",
            "Epoch 17/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9776 - loss: 0.1271 - val_accuracy: 0.9400 - val_loss: 0.1572\n",
            "Epoch 18/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9759 - loss: 0.1153 - val_accuracy: 0.9200 - val_loss: 0.1666\n",
            "Epoch 19/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.1089 - val_accuracy: 0.9300 - val_loss: 0.1499\n",
            "Epoch 20/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9635 - loss: 0.1111 - val_accuracy: 0.9600 - val_loss: 0.1350\n",
            "Epoch 21/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9547 - loss: 0.1367 - val_accuracy: 0.9500 - val_loss: 0.1340\n",
            "Epoch 22/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9815 - loss: 0.1071 - val_accuracy: 0.9500 - val_loss: 0.1330\n",
            "Epoch 23/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9761 - loss: 0.1098 - val_accuracy: 0.9500 - val_loss: 0.1260\n",
            "Epoch 24/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9750 - loss: 0.0982 - val_accuracy: 0.9700 - val_loss: 0.1173\n",
            "Epoch 25/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0866 - val_accuracy: 0.9600 - val_loss: 0.1167\n",
            "Epoch 26/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0948 - val_accuracy: 0.9600 - val_loss: 0.1148\n",
            "Epoch 27/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0900 - val_accuracy: 0.9800 - val_loss: 0.1093\n",
            "Epoch 28/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9789 - loss: 0.0987 - val_accuracy: 0.9600 - val_loss: 0.1092\n",
            "Epoch 29/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9857 - loss: 0.0828 - val_accuracy: 0.9700 - val_loss: 0.1042\n",
            "Epoch 30/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9773 - loss: 0.0939 - val_accuracy: 0.9600 - val_loss: 0.1031\n",
            "Epoch 31/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9852 - loss: 0.0856 - val_accuracy: 0.9600 - val_loss: 0.0976\n",
            "Epoch 32/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0822 - val_accuracy: 0.9900 - val_loss: 0.0921\n",
            "Epoch 33/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9865 - loss: 0.0778 - val_accuracy: 0.9800 - val_loss: 0.0912\n",
            "Epoch 34/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9950 - loss: 0.0699 - val_accuracy: 0.9700 - val_loss: 0.0949\n",
            "Epoch 35/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 0.0754 - val_accuracy: 0.9600 - val_loss: 0.0982\n",
            "Epoch 36/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9917 - loss: 0.0782 - val_accuracy: 0.9800 - val_loss: 0.0882\n",
            "Epoch 37/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9845 - loss: 0.1088 - val_accuracy: 0.9900 - val_loss: 0.0830\n",
            "Epoch 38/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9945 - loss: 0.0773 - val_accuracy: 0.9900 - val_loss: 0.0802\n",
            "Epoch 39/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9754 - loss: 0.0882 - val_accuracy: 0.9800 - val_loss: 0.0852\n",
            "Epoch 40/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9880 - loss: 0.0911 - val_accuracy: 0.9800 - val_loss: 0.0887\n",
            "Epoch 41/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9939 - loss: 0.0702 - val_accuracy: 0.9800 - val_loss: 0.0871\n",
            "Epoch 42/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0674 - val_accuracy: 0.9800 - val_loss: 0.0799\n",
            "Epoch 43/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0721 - val_accuracy: 0.9800 - val_loss: 0.0816\n",
            "Epoch 44/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9940 - loss: 0.0621 - val_accuracy: 0.9800 - val_loss: 0.0760\n",
            "Epoch 45/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9860 - loss: 0.0706 - val_accuracy: 0.9900 - val_loss: 0.0742\n",
            "Epoch 46/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0729 - val_accuracy: 0.9900 - val_loss: 0.0742\n",
            "Epoch 47/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0721 - val_accuracy: 0.9900 - val_loss: 0.0759\n",
            "Epoch 48/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9818 - loss: 0.0723 - val_accuracy: 0.9800 - val_loss: 0.0752\n",
            "Epoch 49/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9904 - loss: 0.0683 - val_accuracy: 0.9900 - val_loss: 0.0741\n",
            "Epoch 50/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9684 - loss: 0.0803 - val_accuracy: 0.9900 - val_loss: 0.0701\n",
            "Epoch 51/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9943 - loss: 0.0782 - val_accuracy: 0.9900 - val_loss: 0.0691\n",
            "Epoch 52/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0575 - val_accuracy: 0.9900 - val_loss: 0.0672\n",
            "Epoch 53/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.0660 - val_accuracy: 0.9900 - val_loss: 0.0669\n",
            "Epoch 54/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0638 - val_accuracy: 0.9800 - val_loss: 0.0715\n",
            "Epoch 55/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0698 - val_accuracy: 0.9800 - val_loss: 0.0731\n",
            "Epoch 56/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9957 - loss: 0.0596 - val_accuracy: 0.9800 - val_loss: 0.0715\n",
            "Epoch 57/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9871 - loss: 0.0725 - val_accuracy: 0.9800 - val_loss: 0.0683\n",
            "Epoch 58/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0542 - val_accuracy: 0.9800 - val_loss: 0.0714\n",
            "Epoch 59/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9929 - loss: 0.0740 - val_accuracy: 0.9900 - val_loss: 0.0645\n",
            "Epoch 60/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9928 - loss: 0.0682 - val_accuracy: 0.9800 - val_loss: 0.0701\n",
            "Epoch 61/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9886 - loss: 0.0700 - val_accuracy: 0.9800 - val_loss: 0.0744\n",
            "Epoch 62/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9951 - loss: 0.0592 - val_accuracy: 0.9800 - val_loss: 0.0705\n",
            "Epoch 63/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9931 - loss: 0.0568 - val_accuracy: 0.9900 - val_loss: 0.0634\n",
            "Epoch 64/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9885 - loss: 0.0714 - val_accuracy: 0.9900 - val_loss: 0.0633\n",
            "Epoch 65/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9956 - loss: 0.0624 - val_accuracy: 0.9900 - val_loss: 0.0627\n",
            "Epoch 66/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9911 - loss: 0.0696 - val_accuracy: 0.9800 - val_loss: 0.0675\n",
            "Epoch 67/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9888 - loss: 0.0617 - val_accuracy: 0.9800 - val_loss: 0.0677\n",
            "Epoch 68/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9847 - loss: 0.0701 - val_accuracy: 0.9800 - val_loss: 0.0644\n",
            "Epoch 69/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0496 - val_accuracy: 0.9800 - val_loss: 0.0632\n",
            "Epoch 70/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9978 - loss: 0.0510 - val_accuracy: 0.9800 - val_loss: 0.0627\n",
            "Epoch 71/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9951 - loss: 0.0586 - val_accuracy: 0.9900 - val_loss: 0.0622\n",
            "Epoch 72/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9810 - loss: 0.0695 - val_accuracy: 0.9800 - val_loss: 0.0679\n",
            "Epoch 73/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0650 - val_accuracy: 0.9800 - val_loss: 0.0623\n",
            "Epoch 74/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0640 - val_accuracy: 0.9900 - val_loss: 0.0592\n",
            "Epoch 75/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0544 - val_accuracy: 0.9800 - val_loss: 0.0623\n",
            "Epoch 76/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0561 - val_accuracy: 0.9800 - val_loss: 0.0646\n",
            "Epoch 77/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9797 - loss: 0.0641 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
            "Epoch 78/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0511 - val_accuracy: 0.9800 - val_loss: 0.0626\n",
            "Epoch 79/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0517 - val_accuracy: 0.9900 - val_loss: 0.0578\n",
            "Epoch 80/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9800 - loss: 0.0657 - val_accuracy: 0.9800 - val_loss: 0.0625\n",
            "Epoch 81/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9928 - loss: 0.0576 - val_accuracy: 1.0000 - val_loss: 0.0559\n",
            "Epoch 82/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0521 - val_accuracy: 0.9900 - val_loss: 0.0618\n",
            "Epoch 83/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9926 - loss: 0.0556 - val_accuracy: 0.9800 - val_loss: 0.0604\n",
            "Epoch 84/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9996 - loss: 0.0478 - val_accuracy: 1.0000 - val_loss: 0.0523\n",
            "Epoch 85/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9956 - loss: 0.0555 - val_accuracy: 1.0000 - val_loss: 0.0544\n",
            "Epoch 86/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0538 - val_accuracy: 0.9800 - val_loss: 0.0620\n",
            "Epoch 87/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0484 - val_accuracy: 0.9900 - val_loss: 0.0559\n",
            "Epoch 88/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9970 - loss: 0.0516 - val_accuracy: 0.9900 - val_loss: 0.0568\n",
            "Epoch 89/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9910 - loss: 0.0603 - val_accuracy: 0.9800 - val_loss: 0.0588\n",
            "Epoch 90/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0506 - val_accuracy: 0.9900 - val_loss: 0.0556\n",
            "Epoch 91/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0544 - val_accuracy: 1.0000 - val_loss: 0.0517\n",
            "Epoch 92/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0646 - val_accuracy: 0.9800 - val_loss: 0.0625\n",
            "Epoch 93/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0543 - val_accuracy: 0.9900 - val_loss: 0.0562\n",
            "Epoch 94/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9962 - loss: 0.0544 - val_accuracy: 0.9900 - val_loss: 0.0531\n",
            "Epoch 95/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0624 - val_accuracy: 0.9800 - val_loss: 0.0571\n",
            "Epoch 96/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9931 - loss: 0.0535 - val_accuracy: 0.9800 - val_loss: 0.0610\n",
            "Epoch 97/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9964 - loss: 0.0517 - val_accuracy: 0.9800 - val_loss: 0.0582\n",
            "Epoch 98/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0448 - val_accuracy: 0.9800 - val_loss: 0.0561\n",
            "Epoch 99/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9934 - loss: 0.0500 - val_accuracy: 0.9900 - val_loss: 0.0532\n",
            "Epoch 100/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0491 - val_accuracy: 0.9900 - val_loss: 0.0565\n",
            "Epoch 101/200\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9966 - loss: 0.0490 - val_accuracy: 0.9800 - val_loss: 0.0577\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Model Evaluation on Test Data:\n",
            "Accuracy: 1.00\n",
            "\n",
            "Model saved as student_exam_predictor.h5\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# ----------------------------\n",
        "# Step 1: Load User Dataset\n",
        "# ----------------------------\n",
        "# Make sure these CSV files are in the same folder as your script\n",
        "train_data = pd.read_csv(\"/content/student_exam_data.csv\")\n",
        "test_data = pd.read_csv(\"/content/student_exam_data_new.csv\")\n",
        "\n",
        "# Display first few rows (optional)\n",
        "print(\"Training Data Sample:\\n\", train_data.head())\n",
        "print(\"Testing Data Sample:\\n\", test_data.head())\n",
        "\n",
        "# ----------------------------\n",
        "# Step 2: Feature and Target Separation\n",
        "# ----------------------------\n",
        "X_train = train_data[['Study Hours', 'Previous Exam Score']].values\n",
        "y_train = train_data['Pass/Fail'].values\n",
        "\n",
        "X_test = test_data[['Study Hours', 'Previous Exam Score']].values\n",
        "y_test = test_data['Pass/Fail'].values\n",
        "\n",
        "# ----------------------------\n",
        "# Step 3: Data Type Conversion and Feature Scaling\n",
        "# ----------------------------\n",
        "\n",
        "# Ensure data types are numerical\n",
        "X_train = X_train.astype(np.float32)\n",
        "y_train = y_train.astype(np.float32)\n",
        "X_test = X_test.astype(np.float32)\n",
        "y_test = y_test.astype(np.float32)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 4: Model Definition\n",
        "# ----------------------------\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001), input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(32, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(1, activation='sigmoid')  # Binary classification output\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ----------------------------\n",
        "# Step 5: Early Stopping Setup\n",
        "# ----------------------------\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "# ----------------------------\n",
        "# Step 6: Model Training\n",
        "# ----------------------------\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=200,\n",
        "    batch_size=16,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# Step 7: Model Evaluation\n",
        "# ----------------------------\n",
        "y_pred_proba = model.predict(X_test)\n",
        "y_pred = (y_pred_proba > 0.5).astype(int) # Convert probabilities to binary predictions\n",
        "\n",
        "# For classification, we should use classification metrics instead of regression metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "# precision = precision_score(y_test, y_pred)\n",
        "# recall = recall_score(y_test, y_pred)\n",
        "# f1 = f1_score(y_test, y_pred)\n",
        "# cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "\n",
        "print(f\"\\n✅ Model Evaluation on Test Data:\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "# print(f\"Precision: {precision:.2f}\")\n",
        "# print(f\"Recall: {recall:.2f}\")\n",
        "# print(f\"F1 Score: {f1:.2f}\")\n",
        "# print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Step 8: Save Model (Optional)\n",
        "# ----------------------------\n",
        "model.save(\"student_exam_predictor.h5\")\n",
        "print(\"\\nModel saved as student_exam_predictor.h5\")"
      ]
    }
  ]
}