{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP0nq34K34NWaTaTOUO3KgK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akanksha-cell-max/Advanced-Artificial-Intelligence/blob/main/Untitled7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sVZ_UwgEjoPc",
        "outputId": "883019a0-bc10-4012-fcc1-82c163231e7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "               IMAGE DENOISING AUTOENCODER\n",
            "======================================================================\n",
            "\n",
            "[STEP 1/6] Generating synthetic dataset...\n",
            "----------------------------------------------------------------------\n",
            "Generating 2000 synthetic image pairs...\n",
            "Generated 0/2000 images\n",
            "Generated 100/2000 images\n",
            "Generated 200/2000 images\n",
            "Generated 300/2000 images\n",
            "Generated 400/2000 images\n",
            "Generated 500/2000 images\n",
            "Generated 600/2000 images\n",
            "Generated 700/2000 images\n",
            "Generated 800/2000 images\n",
            "Generated 900/2000 images\n",
            "Generated 1000/2000 images\n",
            "Generated 1100/2000 images\n",
            "Generated 1200/2000 images\n",
            "Generated 1300/2000 images\n",
            "Generated 1400/2000 images\n",
            "Generated 1500/2000 images\n",
            "Generated 1600/2000 images\n",
            "Generated 1700/2000 images\n",
            "Generated 1800/2000 images\n",
            "Generated 1900/2000 images\n",
            "Successfully generated 2000 image pairs\n",
            "\n",
            "✓ Dataset generated successfully!\n",
            "  - Noisy images shape: (2000, 128, 128, 1)\n",
            "  - Clean images shape: (2000, 128, 128, 1)\n",
            "\n",
            "[STEP 2/6] Splitting dataset...\n",
            "----------------------------------------------------------------------\n",
            "✓ Data split completed!\n",
            "  - Training samples: 1700\n",
            "  - Validation samples: 300\n",
            "\n",
            "[STEP 3/6] Building autoencoder model...\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "✓ Model built successfully!\n",
            "\n",
            "Model Architecture Summary:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"denoising_autoencoder\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"denoising_autoencoder\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m320\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m147,584\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m16\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_2 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m73,792\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_3 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m18,464\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_4 (\u001b[38;5;33mUpSampling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │           \u001b[38;5;34m289\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,792</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,464</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ up_sampling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">UpSampling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m334,593\u001b[0m (1.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">334,593</span> (1.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m333,697\u001b[0m (1.27 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">333,697</span> (1.27 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[STEP 4/6] Training model...\n",
            "----------------------------------------------------------------------\n",
            "Configuration:\n",
            "  - Epochs: 50\n",
            "  - Batch Size: 32\n",
            "  - Learning Rate: 0.001\n",
            "  - Optimizer: Adam\n",
            "  - Loss Function: MSE\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Epoch 1/50\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 0.0613 - mae: 0.1738\n",
            "Epoch 1: val_loss improved from inf to 0.11164, saving model to denoised_output/best_denoising_model.keras\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 4s/step - loss: 0.0608 - mae: 0.1729 - val_loss: 0.1116 - val_mae: 0.2419 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3s/step - loss: 0.0122 - mae: 0.0780\n",
            "Epoch 2: val_loss did not improve from 0.11164\n",
            "\u001b[1m54/54\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 3s/step - loss: 0.0122 - mae: 0.0779 - val_loss: 0.1158 - val_mae: 0.2141 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m15/54\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:30\u001b[0m 4s/step - loss: 0.0073 - mae: 0.0569"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "import cv2\n",
        "from skimage.util import random_noise\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Configuration\n",
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH = 128\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_SAMPLES = 2000  # Number of synthetic images to generate\n",
        "\n",
        "# Data paths\n",
        "CSV_FILE = '/content/sampleSubmission.csv'\n",
        "OUTPUT_DIR = 'denoised_output'\n",
        "\n",
        "# Create output directory\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "\n",
        "class SyntheticDataGenerator:\n",
        "    \"\"\"Generate synthetic clean and noisy images for training\"\"\"\n",
        "\n",
        "    def __init__(self, img_height=128, img_width=128):\n",
        "        self.img_height = img_height\n",
        "        self.img_width = img_width\n",
        "\n",
        "    def add_noise(self, image, noise_type='gaussian'):\n",
        "        \"\"\"Add various types of noise to clean images\"\"\"\n",
        "        noisy_image = image.copy()\n",
        "\n",
        "        if noise_type == 'gaussian':\n",
        "            # Gaussian noise\n",
        "            noise = np.random.normal(0, 0.1, image.shape)\n",
        "            noisy_image = image + noise\n",
        "\n",
        "        elif noise_type == 'salt_pepper':\n",
        "            # Salt and pepper noise\n",
        "            noisy_image = random_noise(image, mode='s&p', amount=0.05)\n",
        "\n",
        "        elif noise_type == 'speckle':\n",
        "            # Speckle noise\n",
        "            noise = np.random.randn(*image.shape)\n",
        "            noisy_image = image + image * noise * 0.2\n",
        "\n",
        "        elif noise_type == 'combined':\n",
        "            # Combined noise (more realistic)\n",
        "            # Gaussian noise\n",
        "            noise = np.random.normal(0, 0.05, image.shape)\n",
        "            noisy_image = image + noise\n",
        "            # Salt and pepper\n",
        "            noisy_image = random_noise(noisy_image, mode='s&p', amount=0.02)\n",
        "            # Add some blur\n",
        "            kernel_size = np.random.choice([3, 5])\n",
        "            noisy_image = cv2.GaussianBlur(noisy_image, (kernel_size, kernel_size), 0)\n",
        "\n",
        "        # Clip values to [0, 1]\n",
        "        noisy_image = np.clip(noisy_image, 0, 1)\n",
        "        return noisy_image.astype(np.float32)\n",
        "\n",
        "    def generate_clean_image(self):\n",
        "        \"\"\"Generate a clean synthetic image (document-like)\"\"\"\n",
        "        img = np.ones((self.img_height, self.img_width), dtype=np.float32)\n",
        "\n",
        "        # Add random text-like patterns\n",
        "        num_lines = np.random.randint(5, 15)\n",
        "        for _ in range(num_lines):\n",
        "            y = np.random.randint(10, self.img_height - 10)\n",
        "            x_start = np.random.randint(10, 40)\n",
        "            x_end = np.random.randint(self.img_width - 40, self.img_width - 10)\n",
        "            thickness = np.random.randint(1, 3)\n",
        "            color = np.random.uniform(0.0, 0.3)\n",
        "            cv2.line(img, (x_start, y), (x_end, y), color, thickness)\n",
        "\n",
        "        # Add random rectangles (like text blocks)\n",
        "        num_rects = np.random.randint(3, 8)\n",
        "        for _ in range(num_rects):\n",
        "            x1 = np.random.randint(5, self.img_width // 2)\n",
        "            y1 = np.random.randint(5, self.img_height // 2)\n",
        "            x2 = x1 + np.random.randint(20, 60)\n",
        "            y2 = y1 + np.random.randint(10, 30)\n",
        "            color = np.random.uniform(0.0, 0.4)\n",
        "            cv2.rectangle(img, (x1, y1), (x2, y2), color, -1)\n",
        "\n",
        "        # Add random circles (like dots)\n",
        "        num_circles = np.random.randint(5, 15)\n",
        "        for _ in range(num_circles):\n",
        "            x = np.random.randint(0, self.img_width)\n",
        "            y = np.random.randint(0, self.img_height)\n",
        "            radius = np.random.randint(1, 4)\n",
        "            color = np.random.uniform(0.0, 0.3)\n",
        "            cv2.circle(img, (x, y), radius, color, -1)\n",
        "\n",
        "        # Apply slight blur for realism\n",
        "        img = cv2.GaussianBlur(img, (3, 3), 0)\n",
        "\n",
        "        return img\n",
        "\n",
        "    def generate_dataset(self, num_samples):\n",
        "        \"\"\"Generate dataset of clean and noisy image pairs\"\"\"\n",
        "        clean_images = []\n",
        "        noisy_images = []\n",
        "\n",
        "        noise_types = ['gaussian', 'salt_pepper', 'speckle', 'combined']\n",
        "\n",
        "        print(f\"Generating {num_samples} synthetic image pairs...\")\n",
        "        for i in range(num_samples):\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Generated {i}/{num_samples} images\")\n",
        "\n",
        "            # Generate clean image\n",
        "            clean_img = self.generate_clean_image()\n",
        "\n",
        "            # Add noise with random type\n",
        "            noise_type = np.random.choice(noise_types)\n",
        "            noisy_img = self.add_noise(clean_img, noise_type)\n",
        "\n",
        "            clean_images.append(clean_img)\n",
        "            noisy_images.append(noisy_img)\n",
        "\n",
        "        print(f\"Successfully generated {len(clean_images)} image pairs\")\n",
        "\n",
        "        # Convert to numpy arrays and add channel dimension\n",
        "        clean_images = np.array(clean_images)[..., np.newaxis]\n",
        "        noisy_images = np.array(noisy_images)[..., np.newaxis]\n",
        "\n",
        "        return noisy_images, clean_images\n",
        "\n",
        "\n",
        "class DenoisingAutoencoder:\n",
        "    \"\"\"Convolutional Autoencoder for image denoising\"\"\"\n",
        "\n",
        "    def __init__(self, input_shape=(128, 128, 1)):\n",
        "        self.input_shape = input_shape\n",
        "        self.model = self.build_model()\n",
        "\n",
        "    def build_model(self):\n",
        "        \"\"\"Build the autoencoder architecture\"\"\"\n",
        "\n",
        "        # Encoder\n",
        "        inputs = layers.Input(shape=self.input_shape)\n",
        "\n",
        "        # Encoding layers\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "        # Decoder\n",
        "        x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "        x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "        x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "        x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "        # Output layer\n",
        "        decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "        # Create model\n",
        "        autoencoder = models.Model(inputs, decoded, name='denoising_autoencoder')\n",
        "\n",
        "        return autoencoder\n",
        "\n",
        "    def compile_model(self, learning_rate=0.001):\n",
        "        \"\"\"Compile the model with optimizer and loss\"\"\"\n",
        "        self.model.compile(\n",
        "            optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "            loss='mse',\n",
        "            metrics=['mae']\n",
        "        )\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"Print model summary\"\"\"\n",
        "        return self.model.summary()\n",
        "\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot training and validation loss\"\"\"\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2)\n",
        "    plt.title('Model Loss Over Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('Loss (MSE)', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['mae'], label='Training MAE', linewidth=2)\n",
        "    plt.plot(history.history['val_mae'], label='Validation MAE', linewidth=2)\n",
        "    plt.title('Model MAE Over Epochs', fontsize=14, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=12)\n",
        "    plt.ylabel('MAE', fontsize=12)\n",
        "    plt.legend(fontsize=10)\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'training_history.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_results(noisy_images, clean_images, denoised_images, num_samples=5):\n",
        "    \"\"\"Visualize noisy, clean, and denoised images\"\"\"\n",
        "    plt.figure(figsize=(15, 3 * num_samples))\n",
        "\n",
        "    for i in range(num_samples):\n",
        "        # Noisy image\n",
        "        plt.subplot(num_samples, 3, i * 3 + 1)\n",
        "        plt.imshow(noisy_images[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "        plt.title('Noisy Input', fontsize=12, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Denoised image\n",
        "        plt.subplot(num_samples, 3, i * 3 + 2)\n",
        "        plt.imshow(denoised_images[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "        plt.title('Denoised Output', fontsize=12, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Clean (ground truth) image\n",
        "        plt.subplot(num_samples, 3, i * 3 + 3)\n",
        "        plt.imshow(clean_images[i].squeeze(), cmap='gray', vmin=0, vmax=1)\n",
        "        plt.title('Clean Ground Truth', fontsize=12, fontweight='bold')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, 'denoising_results.png'), dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def calculate_psnr(original, denoised):\n",
        "    \"\"\"Calculate Peak Signal-to-Noise Ratio\"\"\"\n",
        "    mse = np.mean((original - denoised) ** 2)\n",
        "    if mse == 0:\n",
        "        return float('inf')\n",
        "    max_pixel = 1.0\n",
        "    psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
        "    return psnr\n",
        "\n",
        "\n",
        "def calculate_ssim(original, denoised):\n",
        "    \"\"\"Calculate Structural Similarity Index\"\"\"\n",
        "    from skimage.metrics import structural_similarity as ssim\n",
        "    return ssim(original.squeeze(), denoised.squeeze(), data_range=1.0)\n",
        "\n",
        "\n",
        "def evaluate_model(clean_images, denoised_images):\n",
        "    \"\"\"Evaluate model performance using PSNR, SSIM and MSE\"\"\"\n",
        "    psnr_values = []\n",
        "    ssim_values = []\n",
        "    mse_values = []\n",
        "\n",
        "    for i in range(len(clean_images)):\n",
        "        psnr = calculate_psnr(clean_images[i], denoised_images[i])\n",
        "        ssim_val = calculate_ssim(clean_images[i], denoised_images[i])\n",
        "        mse = np.mean((clean_images[i] - denoised_images[i]) ** 2)\n",
        "\n",
        "        psnr_values.append(psnr)\n",
        "        ssim_values.append(ssim_val)\n",
        "        mse_values.append(mse)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"EVALUATION METRICS\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(f\"Average PSNR: {np.mean(psnr_values):.2f} dB (Higher is better)\")\n",
        "    print(f\"Average SSIM: {np.mean(ssim_values):.4f} (Range: 0-1, closer to 1 is better)\")\n",
        "    print(f\"Average MSE:  {np.mean(mse_values):.6f} (Lower is better)\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    return psnr_values, ssim_values, mse_values\n",
        "\n",
        "\n",
        "def save_sample_images(noisy_images, denoised_images, clean_images, num_samples=10):\n",
        "    \"\"\"Save individual sample images for inspection\"\"\"\n",
        "    samples_dir = os.path.join(OUTPUT_DIR, 'samples')\n",
        "    os.makedirs(samples_dir, exist_ok=True)\n",
        "\n",
        "    for i in range(min(num_samples, len(noisy_images))):\n",
        "        # Save noisy\n",
        "        noisy_img = (noisy_images[i].squeeze() * 255).astype(np.uint8)\n",
        "        cv2.imwrite(os.path.join(samples_dir, f'sample_{i}_noisy.png'), noisy_img)\n",
        "\n",
        "        # Save denoised\n",
        "        denoised_img = (denoised_images[i].squeeze() * 255).astype(np.uint8)\n",
        "        cv2.imwrite(os.path.join(samples_dir, f'sample_{i}_denoised.png'), denoised_img)\n",
        "\n",
        "        # Save clean\n",
        "        clean_img = (clean_images[i].squeeze() * 255).astype(np.uint8)\n",
        "        cv2.imwrite(os.path.join(samples_dir, f'sample_{i}_clean.png'), clean_img)\n",
        "\n",
        "    print(f\"✓ Saved {num_samples} sample images to '{samples_dir}/'\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main training pipeline\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\" \" * 15 + \"IMAGE DENOISING AUTOENCODER\")\n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "    # 1. Generate Synthetic Data\n",
        "    print(\"[STEP 1/6] Generating synthetic dataset...\")\n",
        "    print(\"-\" * 70)\n",
        "    data_generator = SyntheticDataGenerator(IMG_HEIGHT, IMG_WIDTH)\n",
        "    noisy_images, clean_images = data_generator.generate_dataset(NUM_SAMPLES)\n",
        "\n",
        "    print(f\"\\n✓ Dataset generated successfully!\")\n",
        "    print(f\"  - Noisy images shape: {noisy_images.shape}\")\n",
        "    print(f\"  - Clean images shape: {clean_images.shape}\")\n",
        "\n",
        "    # 2. Split data\n",
        "    print(f\"\\n[STEP 2/6] Splitting dataset...\")\n",
        "    print(\"-\" * 70)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        noisy_images, clean_images, test_size=0.15, random_state=42\n",
        "    )\n",
        "\n",
        "    print(f\"✓ Data split completed!\")\n",
        "    print(f\"  - Training samples: {len(X_train)}\")\n",
        "    print(f\"  - Validation samples: {len(X_val)}\")\n",
        "\n",
        "    # 3. Build model\n",
        "    print(f\"\\n[STEP 3/6] Building autoencoder model...\")\n",
        "    print(\"-\" * 70)\n",
        "    autoencoder = DenoisingAutoencoder(input_shape=(IMG_HEIGHT, IMG_WIDTH, 1))\n",
        "    autoencoder.compile_model(learning_rate=LEARNING_RATE)\n",
        "\n",
        "    print(\"\\n✓ Model built successfully!\")\n",
        "    print(\"\\nModel Architecture Summary:\")\n",
        "    autoencoder.summary()\n",
        "\n",
        "    # 4. Train model\n",
        "    print(f\"\\n[STEP 4/6] Training model...\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"Configuration:\")\n",
        "    print(f\"  - Epochs: {EPOCHS}\")\n",
        "    print(f\"  - Batch Size: {BATCH_SIZE}\")\n",
        "    print(f\"  - Learning Rate: {LEARNING_RATE}\")\n",
        "    print(f\"  - Optimizer: Adam\")\n",
        "    print(f\"  - Loss Function: MSE\")\n",
        "    print(\"-\" * 70 + \"\\n\")\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        keras.callbacks.ModelCheckpoint(\n",
        "            os.path.join(OUTPUT_DIR, 'best_denoising_model.keras'),\n",
        "            save_best_only=True,\n",
        "            monitor='val_loss',\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=15,\n",
        "            restore_best_weights=True,\n",
        "            verbose=1\n",
        "        ),\n",
        "        keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss',\n",
        "            factor=0.5,\n",
        "            patience=7,\n",
        "            min_lr=1e-7,\n",
        "            verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "    history = autoencoder.model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 5. Evaluate model\n",
        "    print(f\"\\n[STEP 5/6] Evaluating model performance...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Plot training history\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Generate predictions\n",
        "    print(\"Generating predictions on validation set...\")\n",
        "    denoised_val = autoencoder.model.predict(X_val, verbose=0)\n",
        "\n",
        "    # Calculate metrics\n",
        "    evaluate_model(y_val, denoised_val)\n",
        "\n",
        "    # 6. Visualize and save results\n",
        "    print(f\"[STEP 6/6] Saving results...\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "    # Visualize results\n",
        "    visualize_results(X_val, y_val, denoised_val, num_samples=5)\n",
        "\n",
        "    # Save sample images\n",
        "    save_sample_images(X_val, denoised_val, y_val, num_samples=10)\n",
        "\n",
        "    # Save final model\n",
        "    final_model_path = os.path.join(OUTPUT_DIR, 'final_denoising_model.keras')\n",
        "    autoencoder.model.save(final_model_path)\n",
        "\n",
        "    # Save model architecture diagram\n",
        "    try:\n",
        "        keras.utils.plot_model(\n",
        "            autoencoder.model,\n",
        "            to_file=os.path.join(OUTPUT_DIR, 'model_architecture.png'),\n",
        "            show_shapes=True,\n",
        "            show_layer_names=True,\n",
        "            dpi=150\n",
        "        )\n",
        "        print(f\"✓ Model architecture diagram saved\")\n",
        "    except:\n",
        "        print(\"  (Model architecture diagram not saved - graphviz may not be installed)\")\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"\\nAll outputs saved to '{OUTPUT_DIR}/' directory:\")\n",
        "    print(f\"  ✓ best_denoising_model.keras - Best model checkpoint\")\n",
        "    print(f\"  ✓ final_denoising_model.keras - Final trained model\")\n",
        "    print(f\"  ✓ training_history.png - Training/validation curves\")\n",
        "    print(f\"  ✓ denoising_results.png - Visual comparison results\")\n",
        "    print(f\"  ✓ samples/ - Individual sample images\")\n",
        "    print(f\"\\n{'='*70}\\n\")\n",
        "\n",
        "    return autoencoder, history\n",
        "\n",
        "\n",
        "def denoise_custom_image(model_path, image_path, output_path=None):\n",
        "    \"\"\"Use trained model to denoise a custom image\"\"\"\n",
        "\n",
        "    print(f\"\\nDenoising image: {image_path}\")\n",
        "\n",
        "    # Load model\n",
        "    model = keras.models.load_model(model_path)\n",
        "\n",
        "    # Load and preprocess image\n",
        "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image from {image_path}\")\n",
        "        return\n",
        "\n",
        "    original_shape = img.shape\n",
        "    img_resized = cv2.resize(img, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    img_normalized = img_resized.astype('float32') / 255.0\n",
        "    img_input = img_normalized[np.newaxis, ..., np.newaxis]\n",
        "\n",
        "    # Denoise\n",
        "    print(\"Processing...\")\n",
        "    denoised = model.predict(img_input, verbose=0)\n",
        "    denoised_img = (denoised[0].squeeze() * 255).astype(np.uint8)\n",
        "\n",
        "    # Resize back to original dimensions\n",
        "    denoised_img = cv2.resize(denoised_img, (original_shape[1], original_shape[0]))\n",
        "\n",
        "    # Save result\n",
        "    if output_path is None:\n",
        "        output_path = os.path.join(OUTPUT_DIR, 'denoised_custom.png')\n",
        "\n",
        "    cv2.imwrite(output_path, denoised_img)\n",
        "\n",
        "    # Visualize\n",
        "    plt.figure(figsize=(14, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title('Original Noisy Image', fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.imshow(denoised_img, cmap='gray')\n",
        "    plt.title('Denoised Output', fontsize=14, fontweight='bold')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    comparison_path = output_path.replace('.png', '_comparison.png')\n",
        "    plt.savefig(comparison_path, dpi=300, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"✓ Denoised image saved to: {output_path}\")\n",
        "    print(f\"✓ Comparison saved to: {comparison_path}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Train the model\n",
        "    autoencoder, history = main()\n",
        "\n",
        "    # Example: Denoise a custom image (uncomment and modify path to use)\n",
        "    # denoise_custom_image(\n",
        "    #     os.path.join(OUTPUT_DIR, 'final_denoising_model.keras'),\n",
        "    #     'path/to/your/noisy/image.png',\n",
        "    #     'path/to/output/denoised.png'\n",
        "    # )"
      ]
    }
  ]
}